{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import csv\n",
      "import numpy as np \n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.metrics import accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('train.csv')\n",
      "test = pd.read_csv('test.csv')\n",
      "\n",
      "# get data (will predict test subjects' survival)\n",
      "namesTrain = train.Name\n",
      "survivedTrain = train.Survived\n",
      "namesTest = test.Name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We build a Na\u00efve Bayes classifier to use name data to predict whether people survived or not (and test the min_df parameter to find optimal values). Later, we'll build a RandomForestClassifier for comparison."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, build a 'bag of words' model for names_train. Then, use it to transform (i.e vectorize)\n",
      "# both the training and test sets.\n",
      "cv = CountVectorizer(min_df=1)\n",
      "cv.fit(namesTrain)\n",
      "namesTrainArray = cv.transform(namesTrain).toarray()\n",
      "namesTestArray = cv.transform(namesTest).toarray()\n",
      "\n",
      "# Verify\n",
      "print namesTrainArray.shape, namesTestArray.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(891, 1509) (418, 1509)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Next, build the NB classifier and use it to predict namesTest.\n",
      "# Uncomment if you want to rerun this code.\n",
      "\n",
      "# First, predict and write to CSV file (by ID, name).\n",
      "nb = MultinomialNB()\n",
      "nb.fit(namesTrainArray, survivedTrain)\n",
      "output = nb.predict(namesTrainArray)\n",
      "samplefile = csv.writer(open('sampleNB.csv', 'wb'))\n",
      "samplefile.writerow(['PassengerID', 'Survived'])\n",
      "for idx, item in enumerate(output):\n",
      "    samplefile.writerow([idx, item])\n",
      "    \n",
      "# Test accuracy of training predictions\n",
      "print accuracy_score(survivedTrain, output, normalize=True)\n",
      "\n",
      "# Next, predict and write test predictions to CSV file.\n",
      "output = nb.predict(namesTestArray)\n",
      "# submissionNB = csv.writer(open('submissionNB.csv', 'wb'))\n",
      "# submissionNB.writerow(['PassengerID', 'Survived'])\n",
      "# for idx, item in enumerate(output):\n",
      "#     submissionNB.writerow([892+idx, item])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.905723905724\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmm, looks like there's only about 76% accuracy for the submission we sent into Kaggle. We refine our Na\u00efve Bayes model so we can place higher on the leaderboard. This time, we'll try a GaussianNB instead of a MultinomialNB."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prediction for training set first\n",
      "nb = GaussianNB()\n",
      "nb.fit(namesTrainArray, survivedTrain)\n",
      "output = nb.predict(namesTrainArray)\n",
      "print accuracy_score(survivedTrain, output, normalize=True)\n",
      "\n",
      "# prediction for test set\n",
      "output = nb.predict(namesTestArray)\n",
      "# submissionNB = csv.writer(open('submissionNB.csv', 'wb'))\n",
      "# submissionNB.writerow(['PassengerID', 'Survived'])\n",
      "# for idx, item in enumerate(output):\n",
      "#     submissionNB.writerow([892+idx, item])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.936026936027\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Interesting, GaussianNB still yields ~76.555% accuracy just like last time, although it does slightly better on the training set! I wonder if we can do better with a different model? Let's try running some Random Forests and see if we can do better. We'll still use names this time, of course!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, predict for the training set.\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "rf.fit(namesTrainArray, survivedTrain)\n",
      "output = rf.predict(namesTrainArray)\n",
      "print accuracy_score(survivedTrain, output, normalize=True) # yields 1.0\n",
      "\n",
      "print namesTrainArray.shape\n",
      "print survivedTrain.shape\n",
      "print namesTestArray.shape\n",
      "# now, predict and write to stdout for the test set\n",
      "# output = rf.predict(namesTestArray)\n",
      "# submissionRF = csv.writer(open('submissionRF.csv', 'wb'))\n",
      "# submissionRF.writerow(['PassengerID', 'Survived'])\n",
      "# for idx, item in enumerate(output):\n",
      "#     submissionRF.writerow([892+idx, item])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.998877665544\n",
        "(891, 1509)\n",
        "(891,)\n",
        "(418, 1509)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Excellent, you moved up on the leaderboard by 266 positions! You now have a prediction accuracy of 0.77512 (with 1.0 on the training data). How else might you want to improve your model? From what we've seen with basic modelling, random forests work better than Na\u00efve Bayes for the names data -- let's see what other kinds of ways you might want to improve your model!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We try doubling the number of estimators.\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=200)\n",
      "rf.fit(namesTrainArray, survivedTrain)\n",
      "output = rf.predict(namesTestArray)\n",
      "# submissionRF = csv.writer(open('submissionRF.csv', 'wb'))\n",
      "# submissionRF.writerow(['PassengerID', 'Survived'])\n",
      "# for idx, item in enumerate(output):\n",
      "#     submissionRF.writerow([892+idx, item])\n",
      "\n",
      "# how does it do on the training set?\n",
      "# output_train = rf.predict(namesTrainArray)\n",
      "# print accuracy_score(survivedTrain, output_train, normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears there was no improvement! Let's try another method: instead of bagging (Random Forests), we'll try boosting (Gradient Boosting)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gb = GradientBoostingClassifier()\n",
      "gb.fit(namesTrainArray, survivedTrain)\n",
      "output = rf.predict(namesTestArray)\n",
      "# submissionGB = csv.writer(open('submissionGB.csv', 'wb'))\n",
      "# submissionGB.writerow(['PassengerID', 'Survived'])\n",
      "# for idx, item in enumerate(output):\n",
      "#     submissionGB.writerow([892+idx, item])\n",
      "\n",
      "# how does it do on the training set?\n",
      "# output_train = gb.predict(namesTrainArray)\n",
      "# print accuracy_score(survivedTrain, output_train, normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.843995510662\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Darn, again no improvement! That's the thing about machine learning; it takes lots of persistence to see what works and what doesn't. Let's give Adaboost a shot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ab = AdaBoostClassifier()\n",
      "ab.fit(namesTrainArray, survivedTrain)\n",
      "outputAB = ab.predict(namesTrainArray)\n",
      "print accuracy_score(survivedTrain, outputAB, normalize=True)\n",
      "\n",
      "outputAB = ab.predict(namesTestArray)\n",
      "submissionAB = csv.writer(open('submissionAB.csv', 'wb'))\n",
      "submissionAB.writerow(['PassengerId', 'Survived'])\n",
      "for idx, item in enumerate(output):\n",
      "    submissionAB.writerow([892+idx, item])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.872053872054\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}